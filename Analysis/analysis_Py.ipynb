{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da259bd",
   "metadata": {},
   "source": [
    "# A Behavioral-Economic Demand Analysis of Social Reinforcement\n",
    "### A Python Replication of Schulingkamp et al. (2023), *Frontiers in Psychology*\n",
    "\n",
    "---\n",
    "\n",
    "### Project Objective\n",
    "This notebook provides a complete, reproducible Python workflow for the analyses presented in the following publication:\n",
    "\n",
    "> Schulingkamp, R., Wan, H., & Hackenberg, T. D. (2023). Social familiarity and reinforcement value: a behavioral-economic analysis of demand for social interaction with cagemate and non-cagemate female rats. *Frontiers in Psychology*, *14*, 1158365. https://doi.org/10.3389/fpsyg.2023.1158365\n",
    "\n",
    "The study's goal is to quantify the reinforcing value of social interaction in rats using a behavioral-economic demand analysis. Specifically, it tests how this value is affected by **social familiarity** and **reinforcer magnitude** (duration).\n",
    "\n",
    "This notebook demonstrates two distinct analytical approaches to fitting the **Zero-Bounded Exponential (ZBEn) demand model** to the data:\n",
    "\n",
    "1.  A **frequentist, individual-level analysis** using `lmfit` for nonlinear least-squares.\n",
    "2.  A **Bayesian multilevel analysis** using `pymc` to account for the repeated-measures data structure from a small sample.\n",
    "\n",
    "The data for this study is available in the Supplementary Material of the original publication at the [publisher's website](https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1158365/full#supplementary-material).\n",
    "\n",
    "### Analysis Workflow\n",
    "\n",
    "1.  **Setup & Data Processing**: Loads Python libraries, defines helper functions, and processes the raw data into an analysis-ready format with dummy variables.\n",
    "2.  **Frequentist Analysis (Individual-Level)**: Fits the ZBEn demand model to each rat's data separately and performs linear contrasts on the estimated parameters.\n",
    "3.  **Bayesian Analysis (Multilevel)**: Fits a single, comprehensive Bayesian nonlinear mixed-effects model to the entire dataset, treating individual rats as random effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa33070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment Setup ---\n",
    "#\n",
    "# This cell installs the required Python packages for the analysis.\n",
    "# Uncomment and run this cell only if you are setting up a new environment.\n",
    "\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pandas numpy scipy lmfit pymc arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7bc8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. SETUP: IMPORTS, FUNCTIONS, AND DATA PROCESSING ---\n",
    "\n",
    "# --- 1.1 Load Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from lmfit import Model\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pytensor.tensor as pt\n",
    "from lmfit import Model\n",
    "from scipy.stats import t\n",
    "\n",
    "# Suppress warnings for a cleaner final report\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set pandas display options for consistent formatting\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# --- 1.2 Helper Functions for ZBEn Model ---\n",
    "\n",
    "def transform_IHS(x):\n",
    "    \"\"\"\n",
    "    Inverse Hyperbolic Sine (IHS) transformation.\n",
    "    A log-like transformation that is defined at zero, required by the ZBEn model.\n",
    "    \"\"\"\n",
    "    return np.log10(0.5 * x + np.sqrt(0.25 * (x**2) + 1))\n",
    "\n",
    "def zbe_model_func(FR, f1, f3, f6, u1, u3, u6, \n",
    "                   af1, af3, af6, au1, au3, au6, \n",
    "                   qf1, qf3, qf6, qu1, qu3, qu6):\n",
    "    \"\"\"\n",
    "    Zero-Bounded Exponential (ZBEn) demand model function for lmfit.\n",
    "    This function uses dummy variables (f1, u1, etc.) to estimate a unique\n",
    "    alpha (a) and Q0 (q) for each of the 6 experimental conditions.\n",
    "    \"\"\"\n",
    "    alpha_term = np.exp(af1*f1 + af3*f3 + af6*f6 + au1*u1 + au3*u3 + au6*u6)\n",
    "    q0_term = qf1*f1 + qf3*f3 + qf6*f6 + qu1*u1 + qu3*u3 + qu6*u6\n",
    "    lhs_q0 = transform_IHS(q0_term)\n",
    "    return lhs_q0 * np.exp((-alpha_term / lhs_q0) * q0_term * FR)\n",
    "\n",
    "def summarize_contrasts(posterior_draws):\n",
    "    \"\"\"\n",
    "    Helper function to calculate median and 95% HDI for contrast distributions.\n",
    "    This version is corrected to use xarray syntax before converting to pandas.\n",
    "    \"\"\"\n",
    "    # Calculate quantiles using xarray's method, which creates a 'quantile' coordinate\n",
    "    quantiles = posterior_draws.quantile([0.025, 0.5, 0.975], dim=(\"chain\", \"draw\"))\n",
    "    # Re-label the values of the 'quantile' coordinate\n",
    "    quantiles = quantiles.assign_coords(quantile=['lower_ci', 'median', 'upper_ci'])\n",
    "    # Convert the labeled xarray object to a pandas Series\n",
    "    return quantiles.to_series()\n",
    "\n",
    "# --- 1.3 Load and Process Data ---\n",
    "\n",
    "# Load the raw data from a CSV file\n",
    "raw_demand_df = pd.read_csv(\"Table1.csv\")\n",
    "\n",
    "# --- Process data into an analysis-ready format ---\n",
    "processed_df = raw_demand_df.copy()\n",
    "processed_df['lq'] = transform_IHS(processed_df['Interaction Rate'])\n",
    "processed_df['duration_label'] = processed_df['Social Duration'].replace({\n",
    "    \"10 Sec\": \"10_Sec\", \"30 Sec\": \"30_Sec\", \"60 Sec\": \"60_Sec\"\n",
    "})\n",
    "\n",
    "# Aggregate data by averaging across sessions with the same price (fr)\n",
    "aggregated_df = processed_df.groupby(['Rat', 'Social Familiarity', 'duration_label', 'Social FR'], as_index=False).agg(\n",
    "    interaction_rate=('Interaction Rate', 'mean'),\n",
    "    lq=('lq', 'mean')\n",
    ")\n",
    "aggregated_df = aggregated_df.rename(columns={'Social FR': 'FR'})\n",
    "\n",
    "# --- Create dummy variables for regression models ---\n",
    "# First, create a single interaction-style column for all 6 conditions\n",
    "aggregated_df['condition'] = (aggregated_df['Social Familiarity'] + \"_\" + aggregated_df['duration_label'])\n",
    "\n",
    "# Use pd.get_dummies to create the binary predictor variables\n",
    "model_ready_df = pd.get_dummies(aggregated_df, columns=['condition'], prefix='', prefix_sep='')\n",
    "\n",
    "# Rename columns to be short and valid variable names for model formulas\n",
    "model_ready_df = model_ready_df.rename(columns={\n",
    "    'Cagemate_10_Sec': 'f1',\n",
    "    'Cagemate_30_Sec': 'f3',\n",
    "    'Cagemate_60_Sec': 'f6',\n",
    "    'Non-cagemate_10_Sec': 'u1',\n",
    "    'Non-cagemate_30_Sec': 'u3',\n",
    "    'Non-cagemate_60_Sec': 'u6',\n",
    "    'Social FR': 'FR'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c8212",
   "metadata": {},
   "source": [
    "## 2. Frequentist Analysis (Individual-Level)\n",
    "\n",
    "This section replicates the first analytical approach from the paper, fitting the **Zero-Bounded Exponential (ZBEn) demand model** to each rat's data separately for all experimental conditions. This individual-level method allows for a direct examination of between-subject variability.\n",
    "\n",
    "The ZBEn model is a nonlinear function that describes how consumption of a reinforcer (here, social interaction rate) decreases as its price increases. By fitting this model using the `lmfit` library, we can extract two key parameters that quantify the value of the reinforcer for each condition:\n",
    "\n",
    "-   **$Q_{0}$ (Demand Intensity)**: The predicted level of consumption when the price is zero. A higher $Q_{0}$ indicates a higher overall demand.\n",
    "-   **$\\alpha$ (Elasticity)**: The rate at which consumption decreases as the price increases. A higher $\\alpha$ indicates that demand is more sensitive to price (i.e., more elastic).\n",
    "\n",
    "After fitting the models, we perform linear contrasts on the estimated parameters to test the primary hypotheses: whether social familiarity or interaction duration systematically affected demand intensity ($Q_{0}$) or elasticity ($\\alpha$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675e9480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Estimated ZBEn Parameters (Individual Level) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rat_id</th>\n",
       "      <th>Familiarity</th>\n",
       "      <th>Duration</th>\n",
       "      <th>parameter</th>\n",
       "      <th>estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-4.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-5.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-5.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-5.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-4.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-5.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>47.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>55.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>57.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>46.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>53.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>35.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-5.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-5.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>68.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>94.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>82.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>75.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>65.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>79.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-5.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-5.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-5.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-7.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>51.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>126.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>28.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>93.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>47.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>144.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-7.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>alpha</td>\n",
       "      <td>-6.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>39.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>25.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>18.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>10 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>73.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>30 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>58.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4</td>\n",
       "      <td>Non-cagemate</td>\n",
       "      <td>60 Sec</td>\n",
       "      <td>Q0</td>\n",
       "      <td>63.730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rat_id   Familiarity Duration parameter  estimate\n",
       "0        1      Cagemate   10 Sec     alpha    -4.449\n",
       "1        1      Cagemate   30 Sec     alpha    -5.357\n",
       "2        1      Cagemate   60 Sec     alpha    -5.091\n",
       "3        1  Non-cagemate   10 Sec     alpha    -5.869\n",
       "4        1  Non-cagemate   30 Sec     alpha    -4.194\n",
       "5        1  Non-cagemate   60 Sec     alpha    -5.133\n",
       "6        1      Cagemate   10 Sec        Q0    47.912\n",
       "7        1      Cagemate   30 Sec        Q0    55.078\n",
       "8        1      Cagemate   60 Sec        Q0    57.818\n",
       "9        1  Non-cagemate   10 Sec        Q0    46.336\n",
       "10       1  Non-cagemate   30 Sec        Q0    53.997\n",
       "11       1  Non-cagemate   60 Sec        Q0    35.186\n",
       "12       2      Cagemate   10 Sec     alpha    -6.058\n",
       "13       2      Cagemate   30 Sec     alpha    -5.722\n",
       "14       2      Cagemate   60 Sec     alpha    -6.287\n",
       "15       2  Non-cagemate   10 Sec     alpha    -6.261\n",
       "16       2  Non-cagemate   30 Sec     alpha    -5.864\n",
       "17       2  Non-cagemate   60 Sec     alpha    -6.285\n",
       "18       2      Cagemate   10 Sec        Q0    68.030\n",
       "19       2      Cagemate   30 Sec        Q0    94.035\n",
       "20       2      Cagemate   60 Sec        Q0    82.298\n",
       "21       2  Non-cagemate   10 Sec        Q0    75.047\n",
       "22       2  Non-cagemate   30 Sec        Q0    65.055\n",
       "23       2  Non-cagemate   60 Sec        Q0    79.128\n",
       "24       3      Cagemate   10 Sec     alpha    -5.793\n",
       "25       3      Cagemate   30 Sec     alpha    -5.979\n",
       "26       3      Cagemate   60 Sec     alpha    -5.753\n",
       "27       3  Non-cagemate   10 Sec     alpha    -7.181\n",
       "28       3  Non-cagemate   30 Sec     alpha    -6.552\n",
       "29       3  Non-cagemate   60 Sec     alpha    -6.901\n",
       "30       3      Cagemate   10 Sec        Q0    51.307\n",
       "31       3      Cagemate   30 Sec        Q0   126.632\n",
       "32       3      Cagemate   60 Sec        Q0    28.946\n",
       "33       3  Non-cagemate   10 Sec        Q0    93.298\n",
       "34       3  Non-cagemate   30 Sec        Q0    47.525\n",
       "35       3  Non-cagemate   60 Sec        Q0   144.530\n",
       "36       4      Cagemate   10 Sec     alpha    -6.640\n",
       "37       4      Cagemate   30 Sec     alpha    -6.784\n",
       "38       4      Cagemate   60 Sec     alpha    -6.072\n",
       "39       4  Non-cagemate   10 Sec     alpha    -7.404\n",
       "40       4  Non-cagemate   30 Sec     alpha    -6.451\n",
       "41       4  Non-cagemate   60 Sec     alpha    -6.699\n",
       "42       4      Cagemate   10 Sec        Q0    39.074\n",
       "43       4      Cagemate   30 Sec        Q0    25.022\n",
       "44       4      Cagemate   60 Sec        Q0    18.009\n",
       "45       4  Non-cagemate   10 Sec        Q0    73.798\n",
       "46       4  Non-cagemate   30 Sec        Q0    58.539\n",
       "47       4  Non-cagemate   60 Sec        Q0    63.730"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Linear Contrast Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rat_id</th>\n",
       "      <th>parameter</th>\n",
       "      <th>contrast</th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>t_value</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>alpha</td>\n",
       "      <td>Cagemate vs. Non-cagemate</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>Cagemate vs. Non-cagemate</td>\n",
       "      <td>25.289</td>\n",
       "      <td>107.206</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>alpha</td>\n",
       "      <td>Cagemate vs. Non-cagemate</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Q0</td>\n",
       "      <td>Cagemate vs. Non-cagemate</td>\n",
       "      <td>25.132</td>\n",
       "      <td>99.669</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>alpha</td>\n",
       "      <td>Cagemate vs. Non-cagemate</td>\n",
       "      <td>3.108</td>\n",
       "      <td>0.684</td>\n",
       "      <td>4.547</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Q0</td>\n",
       "      <td>Cagemate vs. Non-cagemate</td>\n",
       "      <td>-78.469</td>\n",
       "      <td>114.623</td>\n",
       "      <td>-0.685</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>alpha</td>\n",
       "      <td>Cagemate vs. Non-cagemate</td>\n",
       "      <td>1.059</td>\n",
       "      <td>0.543</td>\n",
       "      <td>1.951</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Q0</td>\n",
       "      <td>Cagemate vs. Non-cagemate</td>\n",
       "      <td>-113.963</td>\n",
       "      <td>38.391</td>\n",
       "      <td>-2.968</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rat_id parameter                   contrast  estimate  std_error  t_value  \\\n",
       "0       1     alpha  Cagemate vs. Non-cagemate     0.299      0.967    0.310   \n",
       "1       1        Q0  Cagemate vs. Non-cagemate    25.289    107.206    0.236   \n",
       "2       2     alpha  Cagemate vs. Non-cagemate     0.342      0.695    0.491   \n",
       "3       2        Q0  Cagemate vs. Non-cagemate    25.132     99.669    0.252   \n",
       "4       3     alpha  Cagemate vs. Non-cagemate     3.108      0.684    4.547   \n",
       "5       3        Q0  Cagemate vs. Non-cagemate   -78.469    114.623   -0.685   \n",
       "6       4     alpha  Cagemate vs. Non-cagemate     1.059      0.543    1.951   \n",
       "7       4        Q0  Cagemate vs. Non-cagemate  -113.963     38.391   -2.968   \n",
       "\n",
       "   p_value  \n",
       "0    0.761  \n",
       "1    0.817  \n",
       "2    0.629  \n",
       "3    0.803  \n",
       "4    0.000  \n",
       "5    0.501  \n",
       "6    0.061  \n",
       "7    0.006  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 2.1 Define and Fit the ZBEn Demand Model for Each Rat ---\n",
    "\n",
    "# Create an lmfit Model object\n",
    "zbe_lmfit_model = Model(\n",
    "    zbe_model_func, \n",
    "    independent_vars=['FR', 'f1', 'f3', 'f6', 'u1', 'u3', 'u6']\n",
    ")\n",
    "\n",
    "# --- Loop through each rat to fit the model and perform contrasts ---\n",
    "parameter_list = []\n",
    "contrast_list = []\n",
    "for rat_id in model_ready_df['Rat'].unique():\n",
    "    \n",
    "    rat_data = model_ready_df[model_ready_df['Rat'] == rat_id]\n",
    "    \n",
    "    # Set up initial parameter values for the fit\n",
    "    fit_params = zbe_lmfit_model.make_params(\n",
    "        af1=-6, af3=-6, af6=-6, au1=-6, au3=-6, au6=-6,\n",
    "        qf1=50, qf3=50, qf6=50, qu1=50, qu3=50, qu6=50\n",
    "    )\n",
    "    # Constrain Q0 parameters to be non-negative\n",
    "    for p_name in fit_params:\n",
    "        if p_name.startswith('q'):\n",
    "            fit_params[p_name].set(min=0)\n",
    "            \n",
    "    # Define the independent variables for the fit\n",
    "    independent_vars = {\n",
    "        'FR': rat_data['FR'], 'f1': rat_data['f1'], 'f3': rat_data['f3'],\n",
    "        'f6': rat_data['f6'], 'u1': rat_data['u1'], 'u3': rat_data['u3'],\n",
    "        'u6': rat_data['u6']\n",
    "    }\n",
    "    \n",
    "    # Fit the model\n",
    "    result = zbe_lmfit_model.fit(rat_data['lq'], fit_params, **independent_vars)\n",
    "    \n",
    "    # Store the parameter estimates\n",
    "    params_df = pd.DataFrame.from_dict(result.params.valuesdict(), orient='index', columns=['estimate'])\n",
    "    params_df['rat_id'] = rat_id\n",
    "    parameter_list.append(params_df)\n",
    "\n",
    "    # --- Perform Linear Contrasts Manually ---\n",
    "    contrasts_to_test = {\n",
    "        'alpha': {'af1':1, 'af3':1, 'af6':1, 'au1':-1, 'au3':-1, 'au6':-1},\n",
    "        'Q0':    {'qf1':1, 'qf3':1, 'qf6':1, 'qu1':-1, 'qu3':-1, 'qu6':-1}\n",
    "    }\n",
    "    \n",
    "    # Get the covariance matrix and ensure parameter order is correct\n",
    "    covar_matrix = result.covar\n",
    "    param_names = result.var_names\n",
    "\n",
    "    for param_name, expression in contrasts_to_test.items():\n",
    "        # Create a contrast vector C with weights, ordered to match the covariance matrix\n",
    "        contrast_vector = np.array([expression.get(p, 0) for p in param_names])\n",
    "        \n",
    "        # Calculate the contrast estimate: C * B\n",
    "        est = contrast_vector @ np.array([result.params[p].value for p in param_names])\n",
    "        \n",
    "        # Calculate the standard error of the contrast: sqrt(C' * Cov(B) * C)\n",
    "        variance = contrast_vector.T @ covar_matrix @ contrast_vector\n",
    "        stderr = np.sqrt(variance)\n",
    "        \n",
    "        # Calculate t-statistic and two-tailed p-value\n",
    "        t_stat = est / stderr if stderr > 0 else 0\n",
    "        p_val = t.sf(np.abs(t_stat), df=result.nfree) * 2\n",
    "        \n",
    "        contrast_list.append({\n",
    "            'rat_id': rat_id, 'parameter': param_name, 'contrast': 'Cagemate vs. Non-cagemate',\n",
    "            'estimate': est, 'std_error': stderr, 't_value': t_stat, 'p_value': p_val\n",
    "        })\n",
    "\n",
    "# --- 2.2 Format and Display Results ---\n",
    "\n",
    "# Combine parameter estimates from all rats into a single DataFrame\n",
    "individual_parameter_estimates = pd.concat(parameter_list).reset_index().rename(columns={'index': 'term'})\n",
    "individual_parameter_estimates[['parameter_type', 'familiarity_code', 'duration_code']] = \\\n",
    "individual_parameter_estimates['term'].str.extract(r'(a|q)(f|u)(\\d)').fillna('')\n",
    "individual_parameter_estimates['parameter'] = np.where(individual_parameter_estimates['parameter_type'] == 'a', 'alpha', 'Q0')\n",
    "individual_parameter_estimates['Familiarity'] = np.where(individual_parameter_estimates['familiarity_code'] == 'f', 'Cagemate', 'Non-cagemate')\n",
    "individual_parameter_estimates['Duration'] = individual_parameter_estimates['duration_code'].replace({'1':'10 Sec', '3':'30 Sec', '6':'60 Sec'})\n",
    "final_params_df = individual_parameter_estimates[['rat_id', 'Familiarity', 'Duration', 'parameter', 'estimate']]\n",
    "\n",
    "# Combine contrast results into a single DataFrame\n",
    "final_contrasts_df = pd.DataFrame(contrast_list)\n",
    "\n",
    "print(\"--- Estimated ZBEn Parameters (Individual Level) ---\")\n",
    "display(final_params_df)\n",
    "print(\"\\n--- Linear Contrast Results ---\")\n",
    "display(final_contrasts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d4cea",
   "metadata": {},
   "source": [
    "## 3. Bayesian Nonlinear Multilevel Analysis\n",
    "\n",
    "This section presents a more sophisticated analytical approach by fitting a single **Bayesian nonlinear multilevel model** to the entire dataset using `PyMC`. This method offers several advantages over the individual-level frequentist analysis:\n",
    "\n",
    "-   **Principled Regularization**: By treating individual rats as \"random effects,\" the model uses a technique called **partial pooling**. This allows each rat's parameter estimates to be informed by the overall group average, leading to more stable and realistic estimates, especially with small sample sizes.\n",
    "-   **Unified Framework**: Instead of fitting 24 separate models (4 rats x 6 conditions), we fit one comprehensive model. This provides a single, coherent framework for testing hypotheses about the main effects of familiarity and duration.\n",
    "-   **Full Posterior Inference**: This approach yields the full posterior distribution for every parameter and contrast, giving us a complete picture of our uncertainty about the effects.\n",
    "\n",
    "The model estimates fixed effects for the experimental conditions (familiarity and duration) and random effects for each rat's deviation from those fixed effects, directly modeling the between-subject variability within a hierarchical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59f7917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building and Fitting Bayesian Model with PyMC (this may take several minutes) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sd_alpha, z_alpha, sd_q0, z_q0, log_alpha, log_q0, sigma]\n",
      "Sampling 4 chains for 2_000 tune and 2_000 draw iterations (8_000 + 8_000 draws total) took 26 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Posterior Summary for Contrasts on log(alpha) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quantile</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>median</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Familiarity (Cagemate - Non)</th>\n",
       "      <td>0.246</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration (60s - 10s)</th>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quantile                      lower_ci  median  upper_ci\n",
       "Familiarity (Cagemate - Non)     0.246   0.486     0.724\n",
       "Duration (60s - 10s)            -0.083   0.209     0.500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Posterior Summary for Contrasts on log(Q0) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quantile</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>median</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Familiarity (Cagemate - Non)</th>\n",
       "      <td>-0.864</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>-0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration (60s - 10s)</th>\n",
       "      <td>-0.641</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quantile                      lower_ci  median  upper_ci\n",
       "Familiarity (Cagemate - Non)    -0.864  -0.470    -0.074\n",
       "Duration (60s - 10s)            -0.641  -0.174     0.292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3.1 Define and Fit the Bayesian Multilevel Model ---\n",
    "\n",
    "print(\"--- Building and Fitting Bayesian Model with PyMC (this may take several minutes) ---\")\n",
    "\n",
    "# --- Use aggregated_df for the Bayesian model, as it retains the 'condition' column ---\n",
    "bayes_df = aggregated_df.copy()\n",
    "\n",
    "# Define coordinates for the model dimensions\n",
    "condition_names = sorted(bayes_df['condition'].unique())\n",
    "rat_names = sorted(bayes_df['Rat'].unique())\n",
    "coords = {\n",
    "    \"condition\": condition_names,\n",
    "    \"rat\": rat_names,\n",
    "    \"obs_id\": bayes_df.index\n",
    "}\n",
    "\n",
    "# Create numeric indices for mapping observations to the correct parameters\n",
    "rat_idx = pd.Categorical(bayes_df['Rat'], categories=rat_names).codes\n",
    "condition_idx = pd.Categorical(bayes_df['condition'], categories=condition_names).codes\n",
    "\n",
    "with pm.Model(coords=coords) as multilevel_zbe_model:\n",
    "    # --- Priors for Random Effects (Rat-level variability) ---\n",
    "    # Non-centered parameterization for better sampling efficiency\n",
    "    sd_alpha = pm.HalfCauchy(\"sd_alpha\", beta=2.5)\n",
    "    z_alpha = pm.Normal(\"z_alpha\", mu=0, sigma=1, dims=\"rat\")\n",
    "    rat_effect_alpha = pm.Deterministic(\"rat_effect_alpha\", z_alpha * sd_alpha, dims=\"rat\")\n",
    "    \n",
    "    sd_q0 = pm.HalfCauchy(\"sd_q0\", beta=2.5)\n",
    "    z_q0 = pm.Normal(\"z_q0\", mu=0, sigma=1, dims=\"rat\")\n",
    "    rat_effect_q0 = pm.Deterministic(\"rat_effect_q0\", z_q0 * sd_q0, dims=\"rat\")\n",
    "\n",
    "    # --- Priors for Fixed Effects (Condition-level means) ---\n",
    "    # Weakly informative priors based on the frequentist results and theory\n",
    "    # Parameters are estimated on the log scale to ensure they are positive\n",
    "    log_alpha_coeffs = pm.Normal(\"log_alpha\", mu=-6, sigma=2.5, dims=\"condition\")\n",
    "    log_q0_coeffs = pm.Normal(\"log_q0\", mu=4, sigma=2.5, dims=\"condition\")\n",
    "\n",
    "    # --- Combine Fixed and Random Effects ---\n",
    "    log_alpha_est = log_alpha_coeffs[condition_idx] + rat_effect_alpha[rat_idx]\n",
    "    log_q0_est = log_q0_coeffs[condition_idx] + rat_effect_q0[rat_idx]\n",
    "    \n",
    "    alpha = pm.Deterministic(\"alpha\", pt.exp(log_alpha_est), dims=\"obs_id\")\n",
    "    q0 = pm.Deterministic(\"q0\", pt.exp(log_q0_est), dims=\"obs_id\")\n",
    "\n",
    "    # --- ZBEn Model Equation (Likelihood Mu) ---\n",
    "    ihs_q0 = transform_IHS(q0)\n",
    "    mu = ihs_q0 * pt.exp((-alpha / ihs_q0) * q0 * bayes_df['FR'].values)\n",
    "\n",
    "    # --- Likelihood ---\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=2.5)\n",
    "    lq_obs = pm.Normal(\"lq_obs\", mu=mu, sigma=sigma, observed=bayes_df['lq'], dims=\"obs_id\")\n",
    "    \n",
    "    # --- MCMC Sampling ---\n",
    "    idata = pm.sample(draws=2000, tune=2000, chains=4, cores=4, \n",
    "                      target_accept=0.95, progressbar=False)\n",
    "\n",
    "\n",
    "# --- 3.2 Analyze Posterior Contrasts ---\n",
    "\n",
    "# --- Define condition groups for contrasts ---\n",
    "cagemate_conds = [c for c in condition_names if 'Cagemate' in c]\n",
    "non_cagemate_conds = [c for c in condition_names if 'Non-cagemate' in c]\n",
    "conds_10_sec = [c for c in condition_names if '10_Sec' in c]\n",
    "conds_60_sec = [c for c in condition_names if '60_Sec' in c]\n",
    "\n",
    "# --- Extract posterior draws for alpha and Q0 ---\n",
    "posterior_log_alpha = idata.posterior[\"log_alpha\"]\n",
    "posterior_log_q0 = idata.posterior[\"log_q0\"]\n",
    "\n",
    "# --- Calculate Alpha Contrasts ---\n",
    "contrast_alpha_familiarity = (\n",
    "    posterior_log_alpha.sel(condition=cagemate_conds).mean(dim=\"condition\") -\n",
    "    posterior_log_alpha.sel(condition=non_cagemate_conds).mean(dim=\"condition\")\n",
    ")\n",
    "contrast_alpha_duration = (\n",
    "    posterior_log_alpha.sel(condition=conds_60_sec).mean(dim=\"condition\") -\n",
    "    posterior_log_alpha.sel(condition=conds_10_sec).mean(dim=\"condition\")\n",
    ")\n",
    "\n",
    "# --- Calculate Q0 Contrasts ---\n",
    "contrast_q0_familiarity = (\n",
    "    posterior_log_q0.sel(condition=cagemate_conds).mean(dim=\"condition\") -\n",
    "    posterior_log_q0.sel(condition=non_cagemate_conds).mean(dim=\"condition\")\n",
    ")\n",
    "contrast_q0_duration = (\n",
    "    posterior_log_q0.sel(condition=conds_60_sec).mean(dim=\"condition\") -\n",
    "    posterior_log_q0.sel(condition=conds_10_sec).mean(dim=\"condition\")\n",
    ")\n",
    "\n",
    "# --- Format and Display Results ---\n",
    "alpha_contrasts = pd.DataFrame({\n",
    "    'Familiarity (Cagemate - Non)': summarize_contrasts(contrast_alpha_familiarity),\n",
    "    'Duration (60s - 10s)': summarize_contrasts(contrast_alpha_duration)\n",
    "})\n",
    "\n",
    "q0_contrasts = pd.DataFrame({\n",
    "    'Familiarity (Cagemate - Non)': summarize_contrasts(contrast_q0_familiarity),\n",
    "    'Duration (60s - 10s)': summarize_contrasts(contrast_q0_duration)\n",
    "})\n",
    "\n",
    "print(\"\\n\\n--- Posterior Summary for Contrasts on log(alpha) ---\")\n",
    "display(alpha_contrasts.T)\n",
    "\n",
    "print(\"\\n--- Posterior Summary for Contrasts on log(Q0) ---\")\n",
    "display(q0_contrasts.T)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
