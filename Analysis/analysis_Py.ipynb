{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da259bd",
   "metadata": {},
   "source": [
    "# A Behavioral-Economic Demand Analysis of Social Reinforcement\n",
    "### A Python Replication of Schulingkamp et al. (2023), *Frontiers in Psychology*\n",
    "\n",
    "---\n",
    "\n",
    "### Project Objective\n",
    "This notebook provides a complete, reproducible Python workflow for the analyses presented in the following publication:\n",
    "\n",
    "> Schulingkamp, R., Wan, H., & Hackenberg, T. D. (2023). Social familiarity and reinforcement value: a behavioral-economic analysis of demand for social interaction with cagemate and non-cagemate female rats. *Frontiers in Psychology*, *14*, 1158365. https://doi.org/10.3389/fpsyg.2023.1158365\n",
    "\n",
    "The study's goal is to quantify the reinforcing value of social interaction in rats using a behavioral-economic demand analysis. Specifically, it tests how this value is affected by **social familiarity** and **reinforcer magnitude** (duration).\n",
    "\n",
    "This notebook demonstrates two distinct analytical approaches to fitting the **Zero-Bounded Exponential (ZBEn) demand model** to the data:\n",
    "1.  A **frequentist, individual-level analysis** using `lmfit` for nonlinear least-squares.\n",
    "2.  A **Bayesian multilevel analysis** using `pymc` to account for the repeated-measures data structure from a small sample.\n",
    "\n",
    "The data for this study is available in the Supplementary Material of the original publication at the [publisher's website](https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1158365/full#supplementary-material).\n",
    "\n",
    "### Analysis Workflow\n",
    "1.  **Setup & Data Processing**: Loads Python libraries, defines helper functions, and processes the raw data into an analysis-ready format with dummy variables.\n",
    "2.  **Frequentist Analysis (Individual-Level)**: Fits the ZBEn demand model to each rat's data separately and performs linear contrasts on the estimated parameters.\n",
    "3.  **Bayesian Analysis (Multilevel)**: Fits a single, comprehensive Bayesian nonlinear mixed-effects model to the entire dataset, treating individual rats as random effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment Setup ---\n",
    "#\n",
    "# This cell installs the required Python packages for the analysis.\n",
    "# Uncomment and run this cell only if you are setting up a new environment.\n",
    "\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pandas numpy scipy lmfit pymc arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc8ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded successfully.\n",
      "Individual-level data processed and ready for analysis.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>familiarity_label</th>\n",
       "      <th>duration_label</th>\n",
       "      <th>fr</th>\n",
       "      <th>interaction_rate</th>\n",
       "      <th>lq</th>\n",
       "      <th>f1</th>\n",
       "      <th>f3</th>\n",
       "      <th>f6</th>\n",
       "      <th>u1</th>\n",
       "      <th>u3</th>\n",
       "      <th>u6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10_Sec</td>\n",
       "      <td>1</td>\n",
       "      <td>19.099</td>\n",
       "      <td>1.234</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10_Sec</td>\n",
       "      <td>2</td>\n",
       "      <td>6.136</td>\n",
       "      <td>0.799</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10_Sec</td>\n",
       "      <td>5</td>\n",
       "      <td>2.017</td>\n",
       "      <td>0.385</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>10_Sec</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Cagemate</td>\n",
       "      <td>30_Sec</td>\n",
       "      <td>1</td>\n",
       "      <td>24.800</td>\n",
       "      <td>1.381</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair familiarity_label duration_label  fr  interaction_rate    lq     f1  \\\n",
       "0     1          Cagemate         10_Sec   1            19.099 1.234   True   \n",
       "1     1          Cagemate         10_Sec   2             6.136 0.799   True   \n",
       "2     1          Cagemate         10_Sec   5             2.017 0.385   True   \n",
       "3     1          Cagemate         10_Sec  10             0.000 0.000   True   \n",
       "4     1          Cagemate         30_Sec   1            24.800 1.381  False   \n",
       "\n",
       "      f3     f6     u1     u3     u6  \n",
       "0  False  False  False  False  False  \n",
       "1  False  False  False  False  False  \n",
       "2  False  False  False  False  False  \n",
       "3  False  False  False  False  False  \n",
       "4   True  False  False  False  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. SETUP: IMPORTS, FUNCTIONS, AND DATA PROCESSING ---\n",
    "\n",
    "# --- 1.1 Load Libraries ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from lmfit import Model\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "# Suppress warnings for a cleaner final report\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set pandas display options for consistent formatting\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "\n",
    "# --- 1.2 Helper Functions for ZBEn Model ---\n",
    "\n",
    "def transform_IHS(x):\n",
    "    \"\"\"\n",
    "    Inverse Hyperbolic Sine (IHS) transformation.\n",
    "    A log-like transformation that is defined at zero, required by the ZBEn model.\n",
    "    \"\"\"\n",
    "    return np.log10(0.5 * x + np.sqrt(0.25 * (x**2) + 1))\n",
    "\n",
    "\n",
    "# --- 1.3 Load and Process Data ---\n",
    "\n",
    "# Load the raw data from a CSV file\n",
    "raw_demand_df = pd.read_csv(\"dat.csv\")\n",
    "print(\"Raw data loaded successfully.\")\n",
    "\n",
    "# --- Process data into an analysis-ready format ---\n",
    "processed_df = raw_demand_df.copy()\n",
    "processed_df['active_session_hours'] = (processed_df['active_ses_time'] / 60) / 60\n",
    "processed_df['interaction_rate'] = processed_df['interact'] / processed_df['active_session_hours']\n",
    "processed_df['lq'] = transform_IHS(processed_df['interaction_rate'])\n",
    "processed_df['familiarity_label'] = np.where(processed_df['familiarity'] == 1, \"Cagemate\", \"Non_cagemate\")\n",
    "processed_df['duration_label'] = processed_df['cond'].replace({\n",
    "    \"10sec\": \"10_Sec\", \"30sec\": \"30_Sec\", \"60sec\": \"60_Sec\"\n",
    "})\n",
    "\n",
    "# Aggregate data by averaging across sessions with the same price (fr)\n",
    "aggregated_df = processed_df.groupby(['pair', 'familiarity_label', 'duration_label', 'fr'], as_index=False).agg(\n",
    "    interaction_rate=('interaction_rate', 'mean'),\n",
    "    lq=('lq', 'mean')\n",
    ")\n",
    "\n",
    "# --- Create dummy variables for regression models ---\n",
    "# First, create a single interaction-style column for all 6 conditions\n",
    "aggregated_df['condition'] = (\n",
    "    aggregated_df['familiarity_label'] + \"_\" + aggregated_df['duration_label']\n",
    ")\n",
    "\n",
    "# Use pd.get_dummies to create the binary predictor variables\n",
    "model_ready_df = pd.get_dummies(aggregated_df, columns=['condition'], prefix='', prefix_sep='')\n",
    "\n",
    "# Rename columns to be short and valid variable names for model formulas\n",
    "model_ready_df = model_ready_df.rename(columns={\n",
    "    'Cagemate_10_Sec': 'f1',\n",
    "    'Cagemate_30_Sec': 'f3',\n",
    "    'Cagemate_60_Sec': 'f6',\n",
    "    'Non_cagemate_10_Sec': 'u1',\n",
    "    'Non_cagemate_30_Sec': 'u3',\n",
    "    'Non_cagemate_60_Sec': 'u6'\n",
    "})\n",
    "\n",
    "print(\"Individual-level data processed and ready for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c8212",
   "metadata": {},
   "source": [
    "## 2. Frequentist Analysis (Individual-Level)\n",
    "\n",
    "This section replicates the first analytical approach from the paper, fitting the **Zero-Bounded Exponential (ZBEn) demand model** to each rat's data separately for all experimental conditions. This individual-level method allows for a direct examination of between-subject variability.\n",
    "\n",
    "The ZBEn model is a nonlinear function that describes how consumption of a reinforcer (here, social interaction rate) decreases as its price increases. By fitting this model using the `lmfit` library, we can extract two key parameters that quantify the value of the reinforcer for each condition:\n",
    "-   **$Q_{0}$ (Demand Intensity)**: The predicted level of consumption when the price is zero. A higher $Q_{0}$ indicates a higher overall demand.\n",
    "-   **$\\alpha$ (Elasticity)**: The rate at which consumption decreases as the price increases. A higher $\\alpha$ indicates that demand is more sensitive to price (i.e., more elastic).\n",
    "\n",
    "After fitting the models, we perform linear contrasts on the estimated parameters to test the primary hypotheses: whether social familiarity or interaction duration systematically affected demand intensity ($Q_{0}$) or elasticity ($\\alpha$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import Model\n",
    "from scipy.stats import t\n",
    "\n",
    "# --- 2.1 Define and Fit the ZBEn Demand Model for Each Rat ---\n",
    "\n",
    "def zbe_model_func(fr, f1, f3, f6, u1, u3, u6, \n",
    "                   af1, af3, af6, au1, au3, au6, \n",
    "                   qf1, qf3, qf6, qu1, qu3, qu6):\n",
    "    \"\"\"\n",
    "    Zero-Bounded Exponential (ZBEn) demand model function for lmfit.\n",
    "    This function uses dummy variables (f1, u1, etc.) to estimate a unique\n",
    "    alpha (a) and Q0 (q) for each of the 6 experimental conditions.\n",
    "    \"\"\"\n",
    "    alpha_term = np.exp(af1*f1 + af3*f3 + af6*f6 + au1*u1 + au3*u3 + au6*u6)\n",
    "    q0_term = qf1*f1 + qf3*f3 + qf6*f6 + qu1*u1 + qu3*u3 + qu6*u6\n",
    "    lhs_q0 = transform_IHS(q0_term)\n",
    "    return lhs_q0 * np.exp((-alpha_term / lhs_q0) * q0_term * fr)\n",
    "\n",
    "# Create an lmfit Model object\n",
    "zbe_lmfit_model = Model(\n",
    "    zbe_model_func, \n",
    "    independent_vars=['fr', 'f1', 'f3', 'f6', 'u1', 'u3', 'u6']\n",
    ")\n",
    "\n",
    "# --- Loop through each rat to fit the model and perform contrasts ---\n",
    "parameter_list = []\n",
    "contrast_list = []\n",
    "for rat_id in model_ready_df['pair'].unique():\n",
    "    \n",
    "    rat_data = model_ready_df[model_ready_df['pair'] == rat_id]\n",
    "    \n",
    "    # Set up initial parameter values for the fit\n",
    "    fit_params = zbe_lmfit_model.make_params(\n",
    "        af1=-6, af3=-6, af6=-6, au1=-6, au3=-6, au6=-6,\n",
    "        qf1=50, qf3=50, qf6=50, qu1=50, qu3=50, qu6=50\n",
    "    )\n",
    "    # Constrain Q0 parameters to be non-negative\n",
    "    for p_name in fit_params:\n",
    "        if p_name.startswith('q'):\n",
    "            fit_params[p_name].set(min=0)\n",
    "            \n",
    "    # Define the independent variables for the fit\n",
    "    independent_vars = {\n",
    "        'fr': rat_data['fr'], 'f1': rat_data['f1'], 'f3': rat_data['f3'],\n",
    "        'f6': rat_data['f6'], 'u1': rat_data['u1'], 'u3': rat_data['u3'],\n",
    "        'u6': rat_data['u6']\n",
    "    }\n",
    "    \n",
    "    # Fit the model\n",
    "    result = zbe_lmfit_model.fit(rat_data['lq'], fit_params, **independent_vars)\n",
    "    \n",
    "    # Store the parameter estimates\n",
    "    params_df = pd.DataFrame.from_dict(result.params.valuesdict(), orient='index', columns=['estimate'])\n",
    "    params_df['rat_id'] = rat_id\n",
    "    parameter_list.append(params_df)\n",
    "\n",
    "    # --- Perform Linear Contrasts Manually ---\n",
    "    contrasts_to_test = {\n",
    "        'alpha': {'af1':1, 'af3':1, 'af6':1, 'au1':-1, 'au3':-1, 'au6':-1},\n",
    "        'Q0':    {'qf1':1, 'qf3':1, 'qf6':1, 'qu1':-1, 'qu3':-1, 'qu6':-1}\n",
    "    }\n",
    "    \n",
    "    # Get the covariance matrix and ensure parameter order is correct\n",
    "    covar_matrix = result.covar\n",
    "    param_names = result.var_names\n",
    "\n",
    "    for param_name, expression in contrasts_to_test.items():\n",
    "        # Create a contrast vector C with weights, ordered to match the covariance matrix\n",
    "        contrast_vector = np.array([expression.get(p, 0) for p in param_names])\n",
    "        \n",
    "        # Calculate the contrast estimate: C * B\n",
    "        est = contrast_vector @ np.array([result.params[p].value for p in param_names])\n",
    "        \n",
    "        # Calculate the standard error of the contrast: sqrt(C' * Cov(B) * C)\n",
    "        variance = contrast_vector.T @ covar_matrix @ contrast_vector\n",
    "        stderr = np.sqrt(variance)\n",
    "        \n",
    "        # Calculate t-statistic and two-tailed p-value\n",
    "        t_stat = est / stderr if stderr > 0 else 0\n",
    "        p_val = t.sf(np.abs(t_stat), df=result.nfree) * 2\n",
    "        \n",
    "        contrast_list.append({\n",
    "            'rat_id': rat_id, 'parameter': param_name, 'contrast': 'Cagemate vs. Non-cagemate',\n",
    "            'estimate': est, 'std_error': stderr, 't_value': t_stat, 'p_value': p_val\n",
    "        })\n",
    "\n",
    "# --- 2.2 Format and Display Results ---\n",
    "\n",
    "# Combine parameter estimates from all rats into a single DataFrame\n",
    "individual_parameter_estimates = pd.concat(parameter_list).reset_index().rename(columns={'index': 'term'})\n",
    "individual_parameter_estimates[['parameter_type', 'familiarity_code', 'duration_code']] = \\\n",
    "    individual_parameter_estimates['term'].str.extract(r'(a|q)(f|u)(\\d)').fillna('')\n",
    "individual_parameter_estimates['parameter'] = np.where(individual_parameter_estimates['parameter_type'] == 'a', 'alpha', 'Q0')\n",
    "individual_parameter_estimates['Familiarity'] = np.where(individual_parameter_estimates['familiarity_code'] == 'f', 'Cagemate', 'Non-cagemate')\n",
    "individual_parameter_estimates['Duration'] = individual_parameter_estimates['duration_code'].replace({'1':'10 Sec', '3':'30 Sec', '6':'60 Sec'})\n",
    "final_params_df = individual_parameter_estimates[['rat_id', 'Familiarity', 'Duration', 'parameter', 'estimate']]\n",
    "\n",
    "# Combine contrast results into a single DataFrame\n",
    "final_contrasts_df = pd.DataFrame(contrast_list)\n",
    "\n",
    "print(\"--- Estimated ZBEn Parameters (Individual Level) ---\")\n",
    "display(final_params_df)\n",
    "print(\"\\n--- Linear Contrast Results ---\")\n",
    "display(final_contrasts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d4cea",
   "metadata": {},
   "source": [
    "## 3. Bayesian Nonlinear Multilevel Analysis\n",
    "\n",
    "This section presents a more sophisticated analytical approach by fitting a single **Bayesian nonlinear multilevel model** to the entire dataset using `PyMC`. This method offers several advantages over the individual-level frequentist analysis:\n",
    "\n",
    "-   **Principled Regularization**: By treating individual rats as \"random effects,\" the model uses a technique called **partial pooling**. This allows each rat's parameter estimates to be informed by the overall group average, leading to more stable and realistic estimates, especially with small sample sizes.\n",
    "-   **Unified Framework**: Instead of fitting 24 separate models (4 rats x 6 conditions), we fit one comprehensive model. This provides a single, coherent framework for testing hypotheses about the main effects of familiarity and duration.\n",
    "-   **Full Posterior Inference**: This approach yields the full posterior distribution for every parameter and contrast, giving us a complete picture of our uncertainty about the effects.\n",
    "\n",
    "The model estimates fixed effects for the experimental conditions (familiarity and duration) and random effects for each rat's deviation from those fixed effects, directly modeling the between-subject variability within a hierarchical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f59f7917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building and Fitting Bayesian Model with PyMC (this may take several minutes) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sd_alpha, z_alpha, sd_q0, z_q0, log_alpha, log_q0, sigma]\n",
      "Sampling 4 chains for 2_000 tune and 2_000 draw iterations (8_000 + 8_000 draws total) took 23 seconds.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Posterior Summary for Contrasts on log(alpha) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quantile</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>median</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Familiarity (Cagemate - Non)</th>\n",
       "      <td>0.244</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration (60s - 10s)</th>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quantile                      lower_ci  median  upper_ci\n",
       "Familiarity (Cagemate - Non)     0.244   0.480     0.723\n",
       "Duration (60s - 10s)            -0.076   0.214     0.496"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Posterior Summary for Contrasts on log(Q0) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>quantile</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>median</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Familiarity (Cagemate - Non)</th>\n",
       "      <td>-0.873</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>-0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration (60s - 10s)</th>\n",
       "      <td>-0.644</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "quantile                      lower_ci  median  upper_ci\n",
       "Familiarity (Cagemate - Non)    -0.873  -0.467    -0.062\n",
       "Duration (60s - 10s)            -0.644  -0.170     0.305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3.1 Define and Fit the Bayesian Multilevel Model ---\n",
    "\n",
    "print(\"--- Building and Fitting Bayesian Model with PyMC (this may take several minutes) ---\")\n",
    "\n",
    "# --- Use aggregated_df for the Bayesian model, as it retains the 'condition' column ---\n",
    "bayes_df = aggregated_df.copy()\n",
    "\n",
    "# Define coordinates for the model dimensions, a best practice for PyMC\n",
    "condition_names = sorted(bayes_df['condition'].unique())\n",
    "rat_names = sorted(bayes_df['pair'].unique())\n",
    "coords = {\n",
    "    \"condition\": condition_names,\n",
    "    \"rat\": rat_names,\n",
    "    \"obs_id\": bayes_df.index\n",
    "}\n",
    "\n",
    "# Create numeric indices for mapping observations to the correct parameters\n",
    "rat_idx = pd.Categorical(bayes_df['pair'], categories=rat_names).codes\n",
    "condition_idx = pd.Categorical(bayes_df['condition'], categories=condition_names).codes\n",
    "\n",
    "with pm.Model(coords=coords) as multilevel_zbe_model:\n",
    "    # --- Priors for Random Effects (Rat-level variability) ---\n",
    "    # Non-centered parameterization for better sampling efficiency\n",
    "    sd_alpha = pm.HalfCauchy(\"sd_alpha\", beta=2.5)\n",
    "    z_alpha = pm.Normal(\"z_alpha\", mu=0, sigma=1, dims=\"rat\")\n",
    "    rat_effect_alpha = pm.Deterministic(\"rat_effect_alpha\", z_alpha * sd_alpha, dims=\"rat\")\n",
    "    \n",
    "    sd_q0 = pm.HalfCauchy(\"sd_q0\", beta=2.5)\n",
    "    z_q0 = pm.Normal(\"z_q0\", mu=0, sigma=1, dims=\"rat\")\n",
    "    rat_effect_q0 = pm.Deterministic(\"rat_effect_q0\", z_q0 * sd_q0, dims=\"rat\")\n",
    "\n",
    "    # --- Priors for Fixed Effects (Condition-level means) ---\n",
    "    # Weakly informative priors based on the frequentist results and theory\n",
    "    # Parameters are estimated on the log scale to ensure they are positive\n",
    "    log_alpha_coeffs = pm.Normal(\"log_alpha\", mu=-6, sigma=2.5, dims=\"condition\")\n",
    "    log_q0_coeffs = pm.Normal(\"log_q0\", mu=4, sigma=2.5, dims=\"condition\")\n",
    "\n",
    "    # --- Combine Fixed and Random Effects ---\n",
    "    log_alpha_est = log_alpha_coeffs[condition_idx] + rat_effect_alpha[rat_idx]\n",
    "    log_q0_est = log_q0_coeffs[condition_idx] + rat_effect_q0[rat_idx]\n",
    "    \n",
    "    alpha = pm.Deterministic(\"alpha\", pt.exp(log_alpha_est), dims=\"obs_id\")\n",
    "    q0 = pm.Deterministic(\"q0\", pt.exp(log_q0_est), dims=\"obs_id\")\n",
    "\n",
    "    # --- ZBEn Model Equation (Likelihood Mu) ---\n",
    "    ihs_q0 = transform_IHS(q0)\n",
    "    mu = ihs_q0 * pt.exp((-alpha / ihs_q0) * q0 * bayes_df['fr'].values)\n",
    "\n",
    "    # --- Likelihood ---\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=2.5)\n",
    "    lq_obs = pm.Normal(\"lq_obs\", mu=mu, sigma=sigma, observed=bayes_df['lq'], dims=\"obs_id\")\n",
    "    \n",
    "    # --- MCMC Sampling ---\n",
    "    idata = pm.sample(draws=2000, tune=2000, chains=4, cores=4, \n",
    "                      target_accept=0.95, progressbar=False)\n",
    "\n",
    "\n",
    "# --- 3.2 Analyze Posterior Contrasts ---\n",
    "\n",
    "def summarize_contrasts(posterior_draws):\n",
    "    \"\"\"\n",
    "    Helper function to calculate median and 95% HDI for contrast distributions.\n",
    "    This version is corrected to use xarray syntax before converting to pandas.\n",
    "    \"\"\"\n",
    "    # Calculate quantiles using xarray's method, which creates a 'quantile' coordinate\n",
    "    quantiles = posterior_draws.quantile([0.025, 0.5, 0.975], dim=(\"chain\", \"draw\"))\n",
    "    # Re-label the values of the 'quantile' coordinate\n",
    "    quantiles = quantiles.assign_coords(quantile=['lower_ci', 'median', 'upper_ci'])\n",
    "    # Convert the labeled xarray object to a pandas Series\n",
    "    return quantiles.to_series()\n",
    "\n",
    "# --- Define condition groups for contrasts ---\n",
    "cagemate_conds = [c for c in condition_names if 'Cagemate' in c]\n",
    "non_cagemate_conds = [c for c in condition_names if 'Non_cagemate' in c]\n",
    "conds_10_sec = [c for c in condition_names if '10_Sec' in c]\n",
    "conds_60_sec = [c for c in condition_names if '60_Sec' in c]\n",
    "\n",
    "# --- Extract posterior draws for alpha and Q0 ---\n",
    "posterior_log_alpha = idata.posterior[\"log_alpha\"]\n",
    "posterior_log_q0 = idata.posterior[\"log_q0\"]\n",
    "\n",
    "# --- Calculate Alpha Contrasts ---\n",
    "contrast_alpha_familiarity = (\n",
    "    posterior_log_alpha.sel(condition=cagemate_conds).mean(dim=\"condition\") -\n",
    "    posterior_log_alpha.sel(condition=non_cagemate_conds).mean(dim=\"condition\")\n",
    ")\n",
    "contrast_alpha_duration = (\n",
    "    posterior_log_alpha.sel(condition=conds_60_sec).mean(dim=\"condition\") -\n",
    "    posterior_log_alpha.sel(condition=conds_10_sec).mean(dim=\"condition\")\n",
    ")\n",
    "\n",
    "# --- Calculate Q0 Contrasts ---\n",
    "contrast_q0_familiarity = (\n",
    "    posterior_log_q0.sel(condition=cagemate_conds).mean(dim=\"condition\") -\n",
    "    posterior_log_q0.sel(condition=non_cagemate_conds).mean(dim=\"condition\")\n",
    ")\n",
    "contrast_q0_duration = (\n",
    "    posterior_log_q0.sel(condition=conds_60_sec).mean(dim=\"condition\") -\n",
    "    posterior_log_q0.sel(condition=conds_10_sec).mean(dim=\"condition\")\n",
    ")\n",
    "\n",
    "# --- Format and Display Results ---\n",
    "alpha_contrasts = pd.DataFrame({\n",
    "    'Familiarity (Cagemate - Non)': summarize_contrasts(contrast_alpha_familiarity),\n",
    "    'Duration (60s - 10s)': summarize_contrasts(contrast_alpha_duration)\n",
    "})\n",
    "\n",
    "q0_contrasts = pd.DataFrame({\n",
    "    'Familiarity (Cagemate - Non)': summarize_contrasts(contrast_q0_familiarity),\n",
    "    'Duration (60s - 10s)': summarize_contrasts(contrast_q0_duration)\n",
    "})\n",
    "\n",
    "print(\"\\n\\n--- Posterior Summary for Contrasts on log(alpha) ---\")\n",
    "display(alpha_contrasts.T)\n",
    "\n",
    "print(\"\\n--- Posterior Summary for Contrasts on log(Q0) ---\")\n",
    "display(q0_contrasts.T)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
